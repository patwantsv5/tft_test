{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a82acf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\tft_env\\lib\\site-packages\\pytorch_forecasting\\models\\base\\_base_model.py:28: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import polars as polars\n",
    "from tqdm import tqdm\n",
    "from params import const_en, const_ja\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer, NaNLabelEncoder\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "val_df = polars.read_csv((\"TESTDATA/val_df.csv\"),low_memory=False) #used\n",
    "result_tdf = polars.read_csv((\"TESTDATA/result_tdf.csv\"),low_memory=False) #used\n",
    "train_df = polars.read_csv((\"TESTDATA/train_df.csv\"),low_memory=False) #used\n",
    "Const = const_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f0a6b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of dupes columns\n",
    "train_df = train_df.drop([col for col in train_df.columns if col.endswith('.1')])\n",
    "val_df = val_df.drop([col for col in val_df.columns if col.endswith('.1')])\n",
    "result_tdf = result_tdf.drop([col for col in result_tdf.columns if col.endswith('.1')])\n",
    "def cast_columns_to_float(df,cols):\n",
    "    for col in cols:\n",
    "        if col in df.columns:\n",
    "            df = df.with_columns(df[col].cast(polars.Float64).alias(col))\n",
    "    return df\n",
    "float_column = [\n",
    "    Const.V_TARGET_OUTPUT, Const.V_BURNER_OUTPUT, Const.FEEDER1,\n",
    "    Const.FEEDER2, Const.FEEDER3, Const.FEEDER4, Const.FEEDER5,\n",
    "    Const.FEEDER6, Const.FEEDER7, Const.FEEDER8, Const.FEEDER9,\n",
    "    Const.FEEDER10, Const.FEEDER11, Const.FEEDER12, Const.FEEDER13,\n",
    "    Const.FEEDER14, Const.FEEDER15, Const.FEEDER16, Const.FEEDER17,\n",
    "    Const.FEEDER18, Const.FEEDER19, Const.FEEDER20, Const.V_SET_TEMP,\n",
    "    Const.V_AGG_TEMP, Const.V_BAG_TEMP\n",
    "]\n",
    "time_varying_unknown_reals = [\n",
    "    Const.V_BAG_TEMP,\n",
    "    Const.HUMIDITY,\n",
    "    Const.TEMPERATURE,\n",
    "    Const.BAG_INLET_TEMP_RISE_RATE,\n",
    "    Const.V_AGG_TEMP,\n",
    "    Const.AGG_TEMP_RISE_RATE\n",
    "    ]\n",
    "static_reals = [] #\"Wetness of material (sand)\"\n",
    "time_varying_known_reals = [\n",
    "    # \"Sin_Hour\",\n",
    "    # \"Cos_Hour\",\n",
    "    # \"Sin_Month\",\n",
    "    # \"Cos_Month\",\n",
    "    Const.TOTAL_SUPPLY,\n",
    "    Const.FEEDER1,\n",
    "    Const.V_SET_TEMP,\n",
    "    Const.FEEDER2,\n",
    "    Const.FEEDER3,\n",
    "    Const.FEEDER4,\n",
    "    Const.FEEDER5,\n",
    "    Const.FEEDER7,\n",
    "    Const.SUPPLY_TIME_ELAPSED,\n",
    "    Const.COLD_AGG_TIME_ELAPSED\n",
    "]\n",
    "train_df = cast_columns_to_float(train_df, float_column)\n",
    "val_df = cast_columns_to_float(val_df,float_column)\n",
    "result_tdf = cast_columns_to_float(result_tdf, float_column)\n",
    "train_df = train_df.to_pandas()\n",
    "val_df = val_df.to_pandas()\n",
    "result_tdf = result_tdf.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f67fecd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "632136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\tft_env\\lib\\site-packages\\pytorch_forecasting\\data\\timeseries\\_timeseries.py:1847: UserWarning: Min encoder length and/or min_prediction_idx and/or min prediction length and/or lags are too large for 306 series/groups which therefore are not present in the dataset index. This means no predictions can be made for those series. First 10 removed groups: [{'__group_id__operation_id': '10', '__group_id__subsequence_id': 1}, {'__group_id__operation_id': '10', '__group_id__subsequence_id': 2}, {'__group_id__operation_id': '10', '__group_id__subsequence_id': 3}, {'__group_id__operation_id': '10', '__group_id__subsequence_id': 4}, {'__group_id__operation_id': '10', '__group_id__subsequence_id': 5}, {'__group_id__operation_id': '10', '__group_id__subsequence_id': 6}, {'__group_id__operation_id': '11', '__group_id__subsequence_id': 1}, {'__group_id__operation_id': '11', '__group_id__subsequence_id': 2}, {'__group_id__operation_id': '11', '__group_id__subsequence_id': 3}, {'__group_id__operation_id': '11', '__group_id__subsequence_id': 4}]\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\tft_env\\lib\\site-packages\\pytorch_forecasting\\data\\encoders.py:401: UserWarning: Found 2 unknown classes which were set to NaN\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\tft_env\\lib\\site-packages\\pytorch_forecasting\\data\\timeseries\\_timeseries.py:1847: UserWarning: Min encoder length and/or min_prediction_idx and/or min prediction length and/or lags are too large for 12 series/groups which therefore are not present in the dataset index. This means no predictions can be made for those series. First 10 removed groups: [{'__group_id__operation_id': '1', '__group_id__subsequence_id': 1}, {'__group_id__operation_id': '1', '__group_id__subsequence_id': 2}, {'__group_id__operation_id': '1', '__group_id__subsequence_id': 3}, {'__group_id__operation_id': '1', '__group_id__subsequence_id': 4}, {'__group_id__operation_id': '1', '__group_id__subsequence_id': 5}, {'__group_id__operation_id': '1', '__group_id__subsequence_id': 6}, {'__group_id__operation_id': '2', '__group_id__subsequence_id': 1}, {'__group_id__operation_id': '2', '__group_id__subsequence_id': 2}, {'__group_id__operation_id': '2', '__group_id__subsequence_id': 3}, {'__group_id__operation_id': '2', '__group_id__subsequence_id': 4}]\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\tft_env\\lib\\site-packages\\pytorch_forecasting\\data\\timeseries\\_timeseries.py:1709: UserWarning: If predicting, no randomization should be possible - setting stop_randomization=True\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\tft_env\\lib\\site-packages\\pytorch_forecasting\\data\\encoders.py:401: UserWarning: Found 2 unknown classes which were set to NaN\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\tft_env\\lib\\site-packages\\pytorch_forecasting\\data\\encoders.py:401: UserWarning: Found 47 unknown classes which were set to NaN\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\envs\\tft_env\\lib\\site-packages\\pytorch_forecasting\\data\\timeseries\\_timeseries.py:1847: UserWarning: Min encoder length and/or min_prediction_idx and/or min prediction length and/or lags are too large for 282 series/groups which therefore are not present in the dataset index. This means no predictions can be made for those series. First 10 removed groups: [{'__group_id__operation_id': '1', '__group_id__subsequence_id': 1}, {'__group_id__operation_id': '1', '__group_id__subsequence_id': 2}, {'__group_id__operation_id': '1', '__group_id__subsequence_id': 3}, {'__group_id__operation_id': '1', '__group_id__subsequence_id': 4}, {'__group_id__operation_id': '1', '__group_id__subsequence_id': 5}, {'__group_id__operation_id': '1', '__group_id__subsequence_id': 6}, {'__group_id__operation_id': '10', '__group_id__subsequence_id': 1}, {'__group_id__operation_id': '10', '__group_id__subsequence_id': 2}, {'__group_id__operation_id': '10', '__group_id__subsequence_id': 3}, {'__group_id__operation_id': '10', '__group_id__subsequence_id': 4}]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_df[\"operation_id\"] = train_df[\"operation_id\"].astype(str)\n",
    "# train_df[\"subsequence_id\"] = train_df[\"subsequence_id\"].astype(str)\n",
    "result_tdf[\"operation_id\"] = result_tdf[\"operation_id\"].astype(str)\n",
    "\n",
    "val_df[\"operation_id\"] = val_df[\"operation_id\"].astype(str)\n",
    "# val_df[\"subsequence_id\"] = val_df[\"subsequence_id\"].astype(str)\n",
    "\n",
    "print(len(result_tdf))\n",
    "max_prediction_length = 6\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    train_df, #[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=Const.V_TARGET_OUTPUT,\n",
    "    group_ids=[\"operation_id\", \"subsequence_id\"],\n",
    "    min_encoder_length=1,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=300,\n",
    "    min_prediction_length=max_prediction_length, # max_prediction_length â‰¤ shortest_series_length - max_encoder_length\n",
    "    max_prediction_length=max_prediction_length, # max_encoder_length + max_prediction_length â‰¤ series_length\n",
    "    static_categoricals=[\"operation_id\"],\n",
    "    static_reals=static_reals,\n",
    "    # time_varying_known_categoricals=[\"DATE\", \"TIME\"],\n",
    "    # variable_groups={\"special_days\": special_days},  # group of categorical variables can be treated as one variable\n",
    "    time_varying_known_reals=list(time_varying_known_reals),\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=list(time_varying_unknown_reals),\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=[\"operation_id\"], transformation=\"softplus\"\n",
    "    ),  # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    "    categorical_encoders = {\n",
    "        \"operation_id\": NaNLabelEncoder(add_nan=True),\n",
    "        \"subsequence_id\": NaNLabelEncoder(add_nan=True),\n",
    "    # Include all other categorical columns used\n",
    "    },\n",
    ")\n",
    "\n",
    "# create validation set (predict=True) which means to predict the last max_prediction_length points in time\n",
    "# for each series\n",
    "validation = TimeSeriesDataSet.from_dataset(training, val_df, predict=True, stop_randomization=True)\n",
    "test_dataset = TimeSeriesDataSet.from_dataset(training, result_tdf, predict=True,stop_randomization=False)\n",
    "# validation.shape()\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 128  # set this between 32 to 128\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size * 10, num_workers=0)\n",
    "test_dataloader = test_dataset.to_dataloader(train=False,batch_size=batch_size,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c356b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\tft_env\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:210: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "c:\\ProgramData\\anaconda3\\envs\\tft_env\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:210: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\ProgramData\\anaconda3\\envs\\tft_env\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:433: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=21` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.5957)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate baseline mean absolute error, i.e. predict next value as the last available value from the history\n",
    "baseline_predictions = Baseline().predict(val_dataloader, return_y=True)\n",
    "MAE()(baseline_predictions.output, baseline_predictions.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60a7fc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\ProgramData\\anaconda3\\envs\\tft_env\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:210: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "c:\\ProgramData\\anaconda3\\envs\\tft_env\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:210: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 17.0k\n"
     ]
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "pl.seed_everything(42)\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"cpu\",\n",
    "    # clipping gradients is a hyperparameter and important to prevent divergance\n",
    "    # of the gradient for recurrent neural networks\n",
    "    gradient_clip_val=0.1,\n",
    ")\n",
    "\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    # not meaningful for finding the learning rate but otherwise very important\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=8,  # most important hyperparameter apart from learning rate\n",
    "    # number of attention heads. Set to up to 4 for large datasets\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,  # between 0.1 and 0.3 are good values\n",
    "    hidden_continuous_size=8,  # set to <= hidden_size\n",
    "    loss=QuantileLoss(),\n",
    "    optimizer=\"Adam\"\n",
    "    # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    # reduce_on_plateau_patience=1000,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1846ceea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\tft_env\\lib\\site-packages\\lightning\\pytorch\\loops\\utilities.py:73: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "c:\\ProgramData\\anaconda3\\envs\\tft_env\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=21` in the `DataLoader` to improve performance.\n",
      "c:\\ProgramData\\anaconda3\\envs\\tft_env\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=21` in the `DataLoader` to improve performance.\n",
      "Finding best initial lr: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:50<00:00,  1.85it/s]`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Finding best initial lr: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:50<00:00,  1.97it/s]\n",
      "Learning rate set to 0.000331131121482591\n",
      "Restoring states from the checkpoint path at c:\\Users\\3562\\Documents\\TFT_TEST\\new_TFT\\.lr_find_a551149e-bde3-4dc0-8cc8-0bd7a03ccc99.ckpt\n",
      "Restored all states from the checkpoint at c:\\Users\\3562\\Documents\\TFT_TEST\\new_TFT\\.lr_find_a551149e-bde3-4dc0-8cc8-0bd7a03ccc99.ckpt\n",
      "c:\\ProgramData\\anaconda3\\envs\\tft_env\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:433: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=21` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggested learning rate: 0.000331131121482591\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\3562\\AppData\\Local\\Temp\\ipykernel_22416\\4268711780.py:14: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  fig.show()\n"
     ]
    }
   ],
   "source": [
    "# find optimal learning rate\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "\n",
    "res = Tuner(trainer).lr_find(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    max_lr=10.0,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a504a358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5749eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\ProgramData\\anaconda3\\envs\\tft_env\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:210: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "c:\\ProgramData\\anaconda3\\envs\\tft_env\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:210: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 36.2k\n"
     ]
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "logger = CSVLogger(save_dir=os.getcwd(), name=\"logs_csv\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    accelerator=\"auto\",\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,\n",
    "    limit_train_batches=50,  # coment in for training, running valiation every 30 batches\n",
    "    # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=16,\n",
    "    attention_head_size=2,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=8,\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    optimizer=\"Adam\",\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd9d7062",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 780    | train\n",
      "3  | prescalers                         | ModuleDict                      | 320    | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 1.9 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 12.4 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 7.4 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 2.2 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 2.2 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544    | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 32     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 808    | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 576    | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 576    | train\n",
      "20 | output_layer                       | Linear                          | 119    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "36.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "36.2 K    Total params\n",
      "0.145     Total estimated model params size (MB)\n",
      "616       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\tft_env\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:433: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=21` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:37<00:00,  1.34it/s, v_num=13, train_loss_step=1.350, val_loss=2.790, train_loss_epoch=1.110]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:37<00:00,  1.33it/s, v_num=13, train_loss_step=1.350, val_loss=2.790, train_loss_epoch=1.110]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fbe2fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-19 12:07:19,576] A new study created in memory with name: no-name-d4697137-f66e-4b2f-8c4c-202af0f22806\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5.0\n",
      "0.14.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "[I 2025-09-19 12:25:59,854] Trial 0 finished with value: 5.901269912719727 and parameters: {'gradient_clip_val': 0.08084658109222384, 'hidden_size': 127, 'dropout': 0.22213378392170355, 'hidden_continuous_size': 8, 'attention_head_size': 4, 'learning_rate': 0.024079701118835038}. Best is trial 0 with value: 5.901269912719727.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "[I 2025-09-19 12:29:38,089] Trial 1 finished with value: 4.26317024230957 and parameters: {'gradient_clip_val': 0.012016427401965872, 'hidden_size': 10, 'dropout': 0.18851462547719156, 'hidden_continuous_size': 9, 'attention_head_size': 1, 'learning_rate': 0.07078083789433856}. Best is trial 1 with value: 4.26317024230957.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gradient_clip_val': 0.012016427401965872, 'hidden_size': 10, 'dropout': 0.18851462547719156, 'hidden_continuous_size': 9, 'attention_head_size': 1, 'learning_rate': 0.07078083789433856}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# take ages\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "import optuna\n",
    "import statsmodels\n",
    "print(optuna.__version__)\n",
    "print(statsmodels.__version__)\n",
    "# create study\n",
    "study = optimize_hyperparameters(\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    model_path=\"optuna_test\",\n",
    "    n_trials=2,\n",
    "    max_epochs=10,\n",
    "    gradient_clip_val_range=(0.01, 1.0),\n",
    "    hidden_size_range=(8, 128),\n",
    "    hidden_continuous_size_range=(8, 128),\n",
    "    attention_head_size_range=(1, 4),\n",
    "    learning_rate_range=(0.001, 0.1),\n",
    "    dropout_range=(0.1, 0.3),\n",
    "    trainer_kwargs=dict(limit_train_batches=30),\n",
    "    reduce_on_plateau_patience=4,\n",
    "    use_learning_rate_finder=False,  # use Optuna to find ideal learning rate or use in-built learning rate finder\n",
    ")\n",
    "\n",
    "# save study results - also we can resume tuning at a later point in time\n",
    "with open(\"test_study.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(study, fout)\n",
    "\n",
    "# show best hyperparameters\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b0dd4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\tft_env\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:210: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "c:\\ProgramData\\anaconda3\\envs\\tft_env\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:210: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n"
     ]
    }
   ],
   "source": [
    "# load the best model according to the validation loss\n",
    "# (given that we use early stopping, this is not necessarily the last epoch)\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d203f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\ProgramData\\anaconda3\\envs\\tft_env\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:433: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=21` in the `DataLoader` to improve performance.\n"
     ]
    }
   ],
   "source": [
    "# Predict all at once (no manual looping)\n",
    "predictions = best_tft.predict(data=test_dataloader,return_x=True, return_index=True)\n",
    "# if it's a Prediction object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "972f0a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7.3352e-05, 2.9399e-05, 2.2845e-05, 1.8778e-05, 1.3767e-05, 8.5200e-06],\n",
      "        [2.8592e-05, 2.3637e-05, 2.6438e-05, 2.6966e-05, 2.6084e-05, 2.4046e-05],\n",
      "        [3.0516e-05, 2.2492e-05, 2.6628e-05, 2.8215e-05, 2.8493e-05, 2.8248e-05],\n",
      "        ...,\n",
      "        [2.5910e+01, 2.5936e+01, 2.5955e+01, 2.5984e+01, 2.5966e+01, 2.6001e+01],\n",
      "        [2.5947e+01, 2.5974e+01, 2.5992e+01, 2.5970e+01, 2.6003e+01, 2.6091e+01],\n",
      "        [2.5985e+01, 2.6011e+01, 2.5978e+01, 2.6007e+01, 2.6093e+01, 2.6129e+01]])\n",
      "7172\n",
      "11\n",
      "7172\n",
      "      time_idx operation_id  subsequence_id\n",
      "0            1           10               7\n",
      "1            2           10               8\n",
      "2            3           10               9\n",
      "3            4           10              10\n",
      "4            5           10              11\n",
      "...        ...          ...             ...\n",
      "7167       172            2             178\n",
      "7168       173            2             179\n",
      "7169       174            2             180\n",
      "7170       175            2             181\n",
      "7171       176            2             182\n",
      "\n",
      "[7172 rows x 3 columns]\n",
      "{'encoder_cat': tensor([[[1.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [nan],\n",
      "         [nan],\n",
      "         [nan]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [nan],\n",
      "         [nan],\n",
      "         [nan]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         ...,\n",
      "         [nan],\n",
      "         [nan],\n",
      "         [nan]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [nan],\n",
      "         [nan],\n",
      "         [nan]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [nan],\n",
      "         [nan],\n",
      "         [nan]],\n",
      "\n",
      "        [[0.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         ...,\n",
      "         [nan],\n",
      "         [nan],\n",
      "         [nan]]]), 'encoder_cont': tensor([[[-0.9933, -0.4709,  0.4876,  ..., -0.3272, -1.0394, -0.5859],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan]],\n",
      "\n",
      "        [[-0.9867, -0.4709,  0.4876,  ..., -0.3272, -1.0394, -0.5859],\n",
      "         [-0.9867, -0.4709,  0.4876,  ..., -0.3272, -1.0394, -0.5859],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan]],\n",
      "\n",
      "        [[-0.9800, -0.4709,  0.4876,  ..., -0.3272, -1.0394, -0.5859],\n",
      "         [-0.9800, -0.4709,  0.4876,  ..., -0.3272, -1.0394, -0.5859],\n",
      "         [-0.9800, -0.4709,  0.4876,  ..., -0.3272, -1.0394, -0.5859],\n",
      "         ...,\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1600, -0.6412,  0.8002,  ..., -0.3272, -0.8897, -1.1195],\n",
      "         [ 0.1600, -0.6412,  0.8002,  ..., -0.3272, -0.8897, -0.5859],\n",
      "         [ 0.1600, -0.6412,  0.8002,  ..., -0.3272, -0.8897, -0.5859],\n",
      "         ...,\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan]],\n",
      "\n",
      "        [[ 0.1667, -0.6412,  0.8002,  ..., -0.3272, -0.8897, -1.1195],\n",
      "         [ 0.1667, -0.6412,  0.8002,  ..., -0.3272, -0.8897, -0.5859],\n",
      "         [ 0.1667, -0.6412,  0.8002,  ..., -0.3272, -0.8897, -0.5859],\n",
      "         ...,\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan]],\n",
      "\n",
      "        [[ 0.1733, -0.6412,  0.8002,  ..., -0.3272, -0.8897, -1.1195],\n",
      "         [ 0.1733, -0.6412,  0.8002,  ..., -0.3272, -0.8897, -0.5859],\n",
      "         [ 0.1733, -0.6412,  0.8002,  ..., -0.3272, -0.8897, -0.5859],\n",
      "         ...,\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan],\n",
      "         [    nan,     nan,     nan,  ...,     nan,     nan,     nan]]]), 'encoder_target': tensor([[0., 0., 0.,  ..., nan, nan, nan],\n",
      "        [0., 0., 0.,  ..., nan, nan, nan],\n",
      "        [0., 0., 0.,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., nan, nan, nan],\n",
      "        [0., 0., 0.,  ..., nan, nan, nan],\n",
      "        [0., 0., 0.,  ..., nan, nan, nan]]), 'encoder_lengths': tensor([  1,   2,   3,  ..., 174, 175, 176]), 'decoder_cat': tensor([[[1],\n",
      "         [1],\n",
      "         [1],\n",
      "         [1],\n",
      "         [1],\n",
      "         [1]],\n",
      "\n",
      "        [[1],\n",
      "         [1],\n",
      "         [1],\n",
      "         [1],\n",
      "         [1],\n",
      "         [1]],\n",
      "\n",
      "        [[1],\n",
      "         [1],\n",
      "         [1],\n",
      "         [1],\n",
      "         [1],\n",
      "         [1]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]],\n",
      "\n",
      "        [[0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0],\n",
      "         [0]]]), 'decoder_cont': tensor([[[-0.9933, -0.4709,  0.4876,  ..., -0.3272, -1.0394, -0.5859],\n",
      "         [-0.9933, -0.4709,  0.4876,  ..., -0.3272, -1.0394, -0.5859],\n",
      "         [-0.9933, -0.4709,  0.4876,  ..., -0.3272, -1.0394, -0.5859],\n",
      "         [-0.9933, -0.4709,  0.4876,  ..., -0.3272, -1.0394, -0.5859],\n",
      "         [-0.9933, -0.4709,  0.4876,  ..., -0.3272, -1.0394, -0.5859],\n",
      "         [-0.9933, -0.4709,  0.4876,  ...,  0.0870, -1.0394, -0.5859]],\n",
      "\n",
      "        [[-0.9867, -0.4709,  0.4876,  ..., -0.3272, -1.0394, -0.5859],\n",
      "         [-0.9867, -0.4709,  0.4876,  ..., -0.3272, -1.0394, -0.5859],\n",
      "         [-0.9867, -0.4709,  0.4876,  ..., -0.3272, -1.0394, -0.5859],\n",
      "         [-0.9867, -0.4709,  0.4876,  ..., -0.3272, -1.0394, -0.5859],\n",
      "         [-0.9867, -0.4709,  0.4876,  ...,  0.0870, -1.0394, -0.5859],\n",
      "         [-0.9867, -0.4709,  0.4876,  ...,  0.5012, -1.0394, -0.5859]],\n",
      "\n",
      "        [[-0.9800, -0.4709,  0.4876,  ..., -0.3272, -1.0394, -0.5859],\n",
      "         [-0.9800, -0.4709,  0.4876,  ..., -0.3272, -1.0394, -0.5859],\n",
      "         [-0.9800, -0.4709,  0.4876,  ..., -0.3272, -1.0394, -0.5859],\n",
      "         [-0.9800, -0.4709,  0.4876,  ...,  0.0870, -1.0394, -0.5859],\n",
      "         [-0.9800, -0.4709,  0.4876,  ...,  0.5012, -1.0394, -0.5859],\n",
      "         [-0.9800, -0.4709,  0.4876,  ...,  1.3296, -1.0394, -0.5859]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1600, -0.6412,  0.8002,  ..., -0.3272,  1.5216, -0.5859],\n",
      "         [ 0.1600, -0.6412,  0.8002,  ..., -0.3272,  1.5216, -0.5859],\n",
      "         [ 0.1600, -0.6412,  0.8002,  ..., -0.3272,  1.5216, -0.5859],\n",
      "         [ 0.1600, -0.6412,  0.8002,  ..., -0.3272,  1.5216, -0.5859],\n",
      "         [ 0.1600, -0.6412,  0.8002,  ..., -0.3272,  1.5216, -0.5859],\n",
      "         [ 0.1600, -0.6412,  0.8002,  ..., -0.7415,  1.5066, -1.1195]],\n",
      "\n",
      "        [[ 0.1667, -0.6412,  0.8002,  ..., -0.3272,  1.5216, -0.5859],\n",
      "         [ 0.1667, -0.6412,  0.8002,  ..., -0.3272,  1.5216, -0.5859],\n",
      "         [ 0.1667, -0.6412,  0.8002,  ..., -0.3272,  1.5216, -0.5859],\n",
      "         [ 0.1667, -0.6412,  0.8002,  ..., -0.3272,  1.5216, -0.5859],\n",
      "         [ 0.1667, -0.6412,  0.8002,  ..., -0.7415,  1.5066, -1.1195],\n",
      "         [ 0.1667, -0.6412,  0.8002,  ..., -0.3272,  1.5066, -0.5859]],\n",
      "\n",
      "        [[ 0.1733, -0.6412,  0.8002,  ..., -0.3272,  1.5216, -0.5859],\n",
      "         [ 0.1733, -0.6412,  0.8002,  ..., -0.3272,  1.5216, -0.5859],\n",
      "         [ 0.1733, -0.6412,  0.8002,  ..., -0.3272,  1.5216, -0.5859],\n",
      "         [ 0.1733, -0.6412,  0.8002,  ..., -0.7415,  1.5066, -1.1195],\n",
      "         [ 0.1733, -0.6412,  0.8002,  ..., -0.3272,  1.5066, -0.5859],\n",
      "         [ 0.1733, -0.6412,  0.8002,  ..., -0.3272,  1.5066, -0.5859]]]), 'decoder_target': tensor([[ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        ...,\n",
      "        [22., 22., 22., 22., 22., 22.],\n",
      "        [22., 22., 22., 22., 22., 22.],\n",
      "        [22., 22., 22., 22., 22., 22.]]), 'decoder_lengths': tensor([6, 6, 6,  ..., 6, 6, 6]), 'decoder_time_idx': tensor([[  1,   2,   3,   4,   5,   6],\n",
      "        [  2,   3,   4,   5,   6,   7],\n",
      "        [  3,   4,   5,   6,   7,   8],\n",
      "        ...,\n",
      "        [174, 175, 176, 177, 178, 179],\n",
      "        [175, 176, 177, 178, 179, 180],\n",
      "        [176, 177, 178, 179, 180, 181]]), 'groups': tensor([[  0,   6],\n",
      "        [  0,   7],\n",
      "        [  0,   8],\n",
      "        ...,\n",
      "        [ 52, 179],\n",
      "        [ 52, 180],\n",
      "        [ 52, 181]]), 'target_scale': tensor([[ 7.9368, 29.6774],\n",
      "        [ 7.9368, 29.6774],\n",
      "        [ 7.9368, 29.6774],\n",
      "        ...,\n",
      "        [ 7.9368, 29.6774],\n",
      "        [ 7.9368, 29.6774],\n",
      "        [ 7.9368, 29.6774]])}\n"
     ]
    }
   ],
   "source": [
    "print(predictions.output)\n",
    "pred = predictions.output\n",
    "x_data = predictions.x\n",
    "index = predictions.index\n",
    "# y_true = predictions.y\n",
    "\n",
    "# Extract actuals directly from dataloader\n",
    "actuals_list = []\n",
    "for _, y in test_dataloader:\n",
    "    actuals_list.append(y[0])  # y[0] is your target\n",
    "actuals = torch.cat(actuals_list).cpu()\n",
    "\n",
    "\n",
    "print(len(pred))\n",
    "print(len(x_data))\n",
    "print(len(index))\n",
    "print(index)\n",
    "print(x_data)\n",
    "\n",
    "# Put into DataFrame\n",
    "duck = polars.DataFrame({\n",
    "    \"actuals\": actuals.numpy(),\n",
    "    \"predictions\": pred.numpy()\n",
    "    # \"index\" : index.to_numpy().flatten()\n",
    "})\n",
    "index = polars.from_pandas(index)\n",
    "for col in index.columns:\n",
    "    duck = duck.with_columns(index[col].alias(col))\n",
    "\n",
    "# CAST INTEGER\n",
    "duck = duck.with_columns(\n",
    "    polars.col(\"operation_id\").cast(polars.Int64),\n",
    "    polars.col(\"subsequence_id\").cast(polars.Int64),\n",
    "    polars.col(\"time_idx\").cast(polars.Int64)\n",
    ")\n",
    "\n",
    "fox = duck.sort(\"operation_id\")\n",
    "fox = fox.to_pandas()\n",
    "fox.to_csv(\"Fox.csv\")\n",
    "duck = duck.to_pandas()\n",
    "\n",
    "\n",
    "duck.to_csv(\"Bduck.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31cfbde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([32., 32., 32., 32., 32., 32.])\n",
      "7172\n",
      "Replaced arrays with last timestep safely\n"
     ]
    }
   ],
   "source": [
    "print(actuals[83])\n",
    "print(len(actuals))\n",
    "actuals_last = []\n",
    "predictions_last = []\n",
    "# Get t step = 5\n",
    "\n",
    "fox['actuals'] = fox['actuals'].apply(\n",
    "    lambda x: x[max_prediction_length-1] if isinstance(x, (list, tuple, np.ndarray)) else x\n",
    ")\n",
    "\n",
    "fox['predictions'] = fox['predictions'].apply(\n",
    "    lambda x: x[max_prediction_length-1] if isinstance(x, (list, tuple, np.ndarray)) else x\n",
    ")\n",
    "\n",
    "fox.to_csv(\"Updated_Fox.csv\", index=False)\n",
    "print(\"Replaced arrays with last timestep safely\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tft_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
